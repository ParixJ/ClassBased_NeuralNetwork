{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00366344],\n",
       "       [0.9760232 ],\n",
       "       [0.97452139],\n",
       "       [0.03467652]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from BasicNN_Modules import Dense, Sigmoid, MSE\n",
    "import numpy as np\n",
    "\n",
    "# Model setup\n",
    "model = Dense\n",
    "layer1 = model(2, 3)\n",
    "layer2 = model(3, 5)\n",
    "layer3 = model(5, 1)\n",
    "loss = MSE()\n",
    "activation = Sigmoid()\n",
    "\n",
    "# Input initialization :\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = [[0], [1], [1], [0]]\n",
    "\n",
    "# Define function for training :\n",
    "def train(epochs,lr):\n",
    "    for i in range(epochs):\n",
    "\n",
    "        # Forward Pass :\n",
    "        z1 = layer1.forward(x)\n",
    "        a1, d1 = activation.activate(z1)\n",
    "        z2 = layer2.forward(a1)\n",
    "        a2, d2 = activation.activate(z2)\n",
    "        z3 = layer3.forward(a2)\n",
    "        a3, d3 = activation.activate(z3)\n",
    "        l, ld = loss.error(y, a3)\n",
    "\n",
    "        # Backpropagation using chain rule to estimat gradients :\n",
    "        error = ld * d3\n",
    "        grad_output = np.dot(a2.T,error)\n",
    "        grad_boutput = np.sum(error, axis=0)\n",
    "        error = np.dot(error,layer3.weight.T)\n",
    "        delta_hidden2 = error * d2\n",
    "        grad_wh2 = np.dot(a1.T,delta_hidden2)\n",
    "        grad_bh2 = np.sum(error, axis=0)\n",
    "        error = np.dot(delta_hidden2,layer2.weight.T)\n",
    "        delta_hidden1 = error * d1\n",
    "        grad_wh1 = np.dot(x.T,delta_hidden1)\n",
    "        grad_bh1 = np.sum(error, axis=0)\n",
    "\n",
    "        # Uptading weights after gradient estimation :\n",
    "        layer1.weight -= lr * grad_wh1\n",
    "        layer2.weight -= lr * grad_wh2\n",
    "        layer3.weight -= lr * grad_output\n",
    "        layer1.bias -= lr * grad_bh1\n",
    "        layer2.bias -= lr * grad_bh2\n",
    "        layer3.bias -= lr * grad_boutput\n",
    "\n",
    "# Model training :\n",
    "train(10000,0.19)\n",
    "\n",
    "# Testing molde after training :\n",
    "z1 = layer1.forward(x)\n",
    "a1, d1 = activation.activate(z1)\n",
    "z2 = layer2.forward(a1)\n",
    "a2, d2 = activation.activate(z2)\n",
    "z3 = layer3.forward(a2)\n",
    "a3, d3 = activation.activate(z3)\n",
    "l, ld = loss.error(y, a3)\n",
    "a3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
